{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f2194e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "66384e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 1.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 1., 1., 1.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_padding_mask(seq):\n",
    "    # 패딩 처리된 부분을 마스킹합니다.\n",
    "    # 모델이 패딩을 입력으로 취급하지 않도록 \n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "x = tf.constant([[7, 6, 5, 4, 0], [1, 2, 3, 0, 0], [1, 8, 0, 0, 0]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fb18a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    \"\"\"\n",
    "    sin, cos 안에 들어갈 수치를 구하는 함수입니다.\n",
    "    \"\"\"\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    \"\"\"\n",
    "    위치 인코딩(Positional Encoding)을 구하는 함수입니다.\n",
    "    \"\"\"\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1bea5fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead) \n",
    "    but it must be broadcastable for addition.\n",
    "  \n",
    "    Args:\n",
    "        q: query shape == (..., seq_len_q, depth)\n",
    "        k: key shape == (..., seq_len_k, depth)\n",
    "        v: value shape == (..., seq_len_v, depth_v)\n",
    "        mask: Float tensor with shape broadcastable \n",
    "            to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        output, attention_weights\n",
    "    \"\"\"\n",
    "    \n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    \"\"\"\n",
    "    mask가 있을 경우 masking된 자리(mask=1)에는 (-inf)에 해당하는 절댓값이 큰 음수 -1e9(=-10억)을 더해줍니다.\n",
    "    그 값에 softmax를 취해주면 거의 0에 가까운 값이 나옵니다. 그 다음 value 계산시에 반영되지 않습니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "        \n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "    \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8f89f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(**kargs):\n",
    "    \"\"\"\n",
    "    FFNN을 구현한 코드입니다.\n",
    "\n",
    "    Args:\n",
    "        d_model : 모델의 차원입니다.\n",
    "        dff : 은닉층의 차원 수입니다. 논문에서는 2048을 사용하였습니다.\n",
    "    \"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(kargs['dff'], activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(kargs['d_model'])  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "83f152ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = kargs['num_heads']\n",
    "        self.d_model = kargs['d_model']\n",
    "\n",
    "        assert self.d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = self.d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(self.d_model)\n",
    "        self.wk = tf.keras.layers.Dense(self.d_model)\n",
    "        self.wv = tf.keras.layers.Dense(self.d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(kargs['d_model'])\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a84f53f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 레이어\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(**kargs)\n",
    "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7ab70b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = kwargs['d_model']\n",
    "        self.num_layers = kwargs['num_layers']\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(kwargs['vocab_size'], self.d_model)\n",
    "        self.pos_encoding = positional_encoding(kwargs['maximum_position_encoding'], \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(**kwargs) \n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(kwargs['rate'])\n",
    "\n",
    "    def call(self, x, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "877a72e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(**kargs)\n",
    "        self.classification_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        # Keras models prefer if you pass all your inputs in the first argument\n",
    "\n",
    "        enc_padding_mask = self.create_masks(inputs)\n",
    "\n",
    "        enc_output = self.encoder(inputs, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        final_output = self.classification_layer(enc_output[:, 0, :]) # (bs, 1, d_model)\n",
    "\n",
    "        return final_output\n",
    "\n",
    "    def create_masks(self, inputs):\n",
    "        # Encoder padding mask\n",
    "        enc_padding_mask = create_padding_mask(inputs)\n",
    "\n",
    "        return enc_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1ca4ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "MAX_SEQUENCE = 80\n",
    "EPOCHS = 3\n",
    "VALID_SPLIT = 0.1\n",
    "MAX_FEATURES = 20000\n",
    "MAXLEN = 2000\n",
    "\n",
    "kargs = {'num_layers': 2,\n",
    "         'd_model': 512,\n",
    "         'num_heads': 8,\n",
    "         'dff': 2048,\n",
    "         'vocab_size': MAX_FEATURES,\n",
    "         'maximum_position_encoding': MAXLEN,\n",
    "         'rate': 0.1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "89c33bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('moviereviews.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d3e6dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.drop_duplicates(subset=['review'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d00a6f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for idx, text in enumerate(df['review']):\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'[^a-z0-9 ]', '', text)\n",
    "    df['review'][idx] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fd328f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df['review']\n",
    "Y = df['label']\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)\n",
    "\n",
    "# 데이터셋 분리\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, stratify=df['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "169961e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#토큰화\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_words = 3000\n",
    "max_len = 6000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "57381cde",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_pad = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=MAXLEN)\n",
    "X_test_pad = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "acdbd6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 선언\n",
    "model = Transformer(**kargs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f7d28b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=10)\n",
    "\n",
    "#학습시킨 데이터 저장\n",
    "checkpoint_path = 'weights.h5'\n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0e905ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.0828 - accuracy: 0.4860  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.56410, saving model to weights.h5\n",
      "22/22 [==============================] - 1385s 63s/step - loss: 1.0828 - accuracy: 0.4860 - val_loss: 0.6942 - val_accuracy: 0.5641\n",
      "Epoch 2/3\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7247 - accuracy: 0.5075  \n",
      "Epoch 2: val_accuracy did not improve from 0.56410\n",
      "22/22 [==============================] - 1534s 70s/step - loss: 0.7247 - accuracy: 0.5075 - val_loss: 0.6910 - val_accuracy: 0.5577\n",
      "Epoch 3/3\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6967 - accuracy: 0.5391  \n",
      "Epoch 3: val_accuracy did not improve from 0.56410\n",
      "22/22 [==============================] - 1477s 68s/step - loss: 0.6967 - accuracy: 0.5391 - val_loss: 0.7022 - val_accuracy: 0.4551\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(X_train_pad, Y_train, \n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                    verbose=1,\n",
    "                    validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2808c9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 100s 8s/step - loss: 0.6972 - accuracy: 0.4820\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델을 이용하여 테스트\n",
    "test_loss, test_acc = model.evaluate(X_test_pad,  Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "97bfb848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 101s 8s/step - loss: 0.7275 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# best model을 이용한 테스트 데이터 예측 정확도 재확인\n",
    "test_loss, test_acc = model.evaluate(X_test_pad, Y_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
